{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ac80f0-2722-4746-9e58-49083c9d39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import archer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86d056d-88b8-47a0-9a5d-c3b7ae2508a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifei/miniconda3/envs/archer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from archer.environment import BatchedTwentyQuestionsEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "446a5d53-a459-4713-a094-ec48716072ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/yifei/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36c45fc-fa69-4cb9-af08-a48774376fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|█████████████████████████████████| 1.40k/1.40k [00:00<00:00, 5.97MB/s]\n",
      "model.safetensors: 100%|██████████████████████████████| 308M/308M [00:00<00:00, 518MB/s]\n",
      "generation_config.json: 100%|██████████████████████████| 147/147 [00:00<00:00, 1.00MB/s]\n"
     ]
    }
   ],
   "source": [
    "env = BatchedTwentyQuestionsEnv(env_load_path = \"/home/yifei/llm_rl/LLM_RL/20q_t5_oracle.pt\", cache_dir = \"/home/yifei/.cache\", device = \"cuda:0\", bsize = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8419291b-1c66-4424-afcd-8486b902718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b0389e-7fde-4380-8391-23608560c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████| 2/2 [00:10<00:00,  5.09s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers \n",
    "import torch\n",
    "model_lm = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_lm)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_lm).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "26b5c2ac-6e85-4a20-b9dc-545ccf0dd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<s>[INST] <<SYS>><</SYS>>\n",
    "\n",
    "{user_message}[/INST]\n",
    "\"\"\"\n",
    "prompt = \"\"\"Please play Twenty Questions with me. \n",
    "An example is:\n",
    "Questions:\n",
    "Is the object alive? Yes.\n",
    "Is the object a mammal? No.\n",
    "Is the object a plant? Yes.\n",
    "Is the object edible? Yes.\n",
    "Is the object a fruit? Yes.\n",
    "Is the object a tropical fruit? Yes.\n",
    "Is the object a banana? Yes.\n",
    "\n",
    "Please continue this conversation by completing the next question.\n",
    "{obs}\n",
    "Please answer in the following format:\n",
    "{\n",
    "\"Question\": \"Your Question\",\n",
    "}\n",
    "The possible hidden words are:\n",
    "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
    "\"\"\"\n",
    "TEMPLATE =  prompt_template.format(user_message = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3acc5f4c-c039-4708-9c4c-406496c374b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_actions(output):\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens = True)\n",
    "    actions = []\n",
    "    for a in output:\n",
    "        # action = a.split(\":\")[-1]\n",
    "        # if not \"?\" in action:\n",
    "        #     print(a)\n",
    "        # action = action.split(\"?\")[0]+\"?\"\n",
    "        action = a.split('\"Question\":')[-1]\n",
    "        action = action.split(\"?\")[0] + \"?\"\n",
    "        action = action.strip().replace('\"', '')\n",
    "        actions.append(action)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c613a80-14d6-4b82-b5e6-eee5c823974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                  | 1/100 [00:31<51:25, 31.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "[INST] <<SYS>><</SYS>>\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Questions:\n",
      "Is the object alive? No.\n",
      "\n",
      "-20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                | 1/100 [01:02<1:42:18, 62.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m prompt \u001b[38;5;241m=\u001b[39m TEMPLATE\u001b[38;5;241m.\u001b[39mformat(obs \u001b[38;5;241m=\u001b[39m obs)\n\u001b[1;32m     10\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m obs, r, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(decode_actions(output))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n",
      "File \u001b[0;32m~/miniconda3/envs/archer/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/archer/lib/python3.10/site-packages/transformers/generation/utils.py:1525\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1518\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1519\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1520\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1522\u001b[0m     )\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1542\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1543\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1549\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/archer/lib/python3.10/site-packages/transformers/generation/utils.py:2658\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2658\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2660\u001b[0m \u001b[38;5;66;03m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "for _ in tqdm(range(100)):\n",
    "    episode_reward = 0\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        prompt = TEMPLATE.format(obs = obs)\n",
    "        input_ids = tokenizer(prompt, return_tensors = \"pt\").to(\"cuda:0\")\n",
    "        context_len = input_ids['attention_mask'].size(1)\n",
    "        output = model.generate(**input_ids, max_new_tokens=48, do_sample = True, temperature = 1.0)\n",
    "        obs, r, done = env.step(decode_actions(output[:, context_len:]))[0]\n",
    "        episode_reward += r\n",
    "    print(obs)\n",
    "    histories.append(episode_reward)\n",
    "    print(np.mean(histories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4939d392-7eee-4394-9624-62c78ae5a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()[0]\n",
    "obs, _, _ = env.step([\"Is the object a living thing?\"])[0]\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "59253aae-a656-4369-94fb-b535683e18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = TEMPLATE.replace(\"{obs}\", obs)\n",
    "input_ids = tokenizer(prompt, return_tensors = \"pt\").to(\"cuda:0\")\n",
    "context_len = input_ids['attention_mask'].size(1)\n",
    "output = model.generate(**input_ids, max_new_tokens=64, do_sample = True, temperature = 1.0)\n",
    "obs, r, done = env.step(decode_actions(output[:, context_len:]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "be03e125-7bd3-4431-893d-dfa213dc6166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "Is the object a living thing? No.\n",
      "Is the object a man-made object? Yes.\n",
      "Is the object something you can hold in your hand? Yes.\n",
      "Is the object something you can sit on? No.\n",
      "Is the object something you can write with? No.\n",
      "Is the object you're thinking of something that can be worn on the body? No.\n",
      "Is the object you're thinking of something that can be used for recreational purposes? No.\n",
      "Is the object you're thinking of something that can be used for creative purposes? Yes.\n",
      "Is the object you're thinking of something that can be used for artistic expression? Yes.\n",
      "Is the object you're thinking of something that can be used for decoration? No.\n",
      "Is the object you're thinking of something that can be used for creative writing? Yes.\n",
      "Is the object you're thinking of something that can be used for creative writing? Yes.\n",
      "Is the object you're thinking of something that can be used for creative writing? Yes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b85aeea2-e347-41ba-b183-d1e0af07353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32002 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: <|im_start|>user\n",
      "\n",
      "Please play Twenty Questions with me. The possible hidden words are:\n",
      "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
      "An example is:\n",
      "Is the object alive? Yes.\n",
      "Is the object a mammal? No.\n",
      "Is the object a plant? Yes.\n",
      "Is the object edible? Yes.\n",
      "Is the object a fruit? Yes.\n",
      "Is the object a tropical fruit? Yes.\n",
      "Is the object a banana? Yes.\n",
      "\n",
      "Please continue this conversation by completing the next question.\n",
      "Questions:\n",
      "Is this object alive? No.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Sí, es un animal viviente.\n",
      "No es una planta, porque no tiene vía vegetal para florecer o descansar. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "Please play Twenty Questions with me. The possible hidden words are:\n",
    "football, dog, banana, truck, pants, computer, piano, chair, pen, scissors.\n",
    "An example is:\n",
    "Is the object alive? Yes.\n",
    "Is the object a mammal? No.\n",
    "Is the object a plant? Yes.\n",
    "Is the object edible? Yes.\n",
    "Is the object a fruit? Yes.\n",
    "Is the object a tropical fruit? Yes.\n",
    "Is the object a banana? Yes.\n",
    "\n",
    "Please continue this conversation by completing the next question.\n",
    "Questions:\n",
    "Is this object alive? No.\n",
    "\"\"\"\n",
    "formatted_prompt = (\n",
    "    f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "sequences = pipeline(\n",
    "    formatted_prompt,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p = 0.9,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.1,\n",
    "    max_new_tokens=32,\n",
    "    eos_token_id=CHAT_EOS_TOKEN_ID,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33719bc-2152-4fe9-94f9-e05f5e1b784a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
