# Adversarial Attack Config
defaults:
 - _self_

#cache directory of transformer
cache_dir: '/global/scratch/users/yifeizhou/.cache'
#token
huggingface_token: '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'

env_load_path: '../LLM_rep_RL/simple_game/'
checkpoint_path: '/global/scratch/users/yifeizhou/20q/llama1b_bc_20q.pt'
save_path: '/global/scratch/users/yifeizhou/20q/ckpt/dqn_20q__llama1b_1'

#bc dataset
bc_data_cutoff: 50
bc_num_trajectories: 1000

# env
env_name: twenty_questions
policy_lm: "TinyLlama/TinyLlama-1.1B-Chat-v0.4"
agent_type: "dqn"

#training hyperparameters
beta: 0.0
capacity: 10000
rollout_size: 32
eval_size: 32
warmup_size: 0
batch_size: 4
iterations: 2000
epochs: 50
ppo_epochs: 3
clip_range: 0.1
warmup_iter: 20
grad_accum_steps: 64
actor_update_freq: 1
do_sample: True
temperature: 1.0
critic_lr: 1e-5 #in effect gets multiplied by grad_accum_steps
lm_lr: 5e-8   #in effect gets multiplied by grad_accum_steps * batch_size for llama1b models
env_idx: null #set to null if don't want to reset to a specific environment
gamma: 0.95
tau: 0.1
max_grad_norm: 1.0

use_wandb: True
wandb_key: "bc507b560ebcfd048dff040741fcebae2184bd59"
project_name: 'llm_rl_20q_llama1b'
run_name: 'test-dqn-acc-2-128-lr5e-8-bf16'