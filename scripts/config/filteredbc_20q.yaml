# Adversarial Attack Config
defaults:
 - _self_

#cache directory of transformer
cache_dir: '/global/scratch/users/yifeizhou/.cache'
#token
huggingface_token: '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'

env_load_path: '/global/scratch/users/yifeizhou/20q/jericho_games/z-machine-games-master/jericho-game-suite/spellbrkr.z3'
checkpoint_path: '/global/scratch/users/yifeizhou/20q/twenty_questions_gpt2_model0_full.pt'
policy_lm: "gpt2"
agent_type: "dqn"

#bc dataset
bc_data_cutoff: 50
bc_num_trajectories: 1000


# env
env_name: twenty_questions

#training hyperparameters
capacity: 50000
beta: 0.0
rollout_size: 32
warmup_size: 0
batch_size: 8
iterations: 2000
epochs: 10 #TODO
ppo_epochs: 3
clip_range: 0.1
warmup_iter: 20 #TODO
grad_accum_steps: 32
actor_update_freq: 1
do_sample: True
temperature: 1.0
critic_lr: 2e-5
lm_lr: 4e-6
env_idx: null #set to null if don't want to reset to a specific environment
gamma: 0.95
tau: 0.1

use_wandb: True #TODO
wandb_key: "bc507b560ebcfd048dff040741fcebae2184bd59"
project_name: 'llm_rl_20q'
run_name: 'online_filteredbc'
